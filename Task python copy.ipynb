{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T09:31:28.406599Z",
     "start_time": "2019-08-05T09:31:28.053515Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считываем данные\n",
    "data = pd.read_excel('multisim_dataset.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].fillna('NaN', inplace = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработаем тип datetime64\n",
    "data.tp_change_date = data.tp_change_date.apply(pd.to_datetime)\n",
    "data['mon'] = data.tp_change_date.apply(lambda x : x.month)\n",
    "data['hour'] = data.tp_change_date.apply(lambda x : x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отделим категориальные признаки и вещественные\n",
    "categorical_cols = ['sim_type', 'state_code']\n",
    "numeric_cols = list(set(data.columns.values.tolist()) - set(categorical_cols + ['target'] + ['tp_change_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим данные для обучения на те, которые мы знаем значение target, и те, для которых нам надо его посчитать\n",
    "data2 = data[data['target'] == 'NaN']\n",
    "data1 = data[data['target'] != 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим на Х и у, заполним пропуски нулями для вещественных, категориальные заполним новым признаком NA\n",
    "X = data1[numeric_cols + categorical_cols]\n",
    "y = data1['target']\n",
    "\n",
    "X_real_zeros = X[numeric_cols]\n",
    "X_real_zeros.fillna(0, inplace = True)\n",
    "\n",
    "X_cat = X[categorical_cols]\n",
    "X_cat = pd.DataFrame(X_cat.fillna('NA'))\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим уникальные категориальные признаки, закодируем их и подставим в столбец кат признаков преобразованные признаки\n",
    "X_unic = pd.DataFrame(X_cat.drop_duplicates())\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "encoder = DV(sparse = False)\n",
    "X_cat_oh = encoder.fit_transform(X_unic.T.to_dict().values())\n",
    "\n",
    "a = []\n",
    "for i in range(235):\n",
    "    a.insert(i, [X_unic.values[i], X_cat_oh[i]])\n",
    "\n",
    "X_cat_n = []\n",
    "k = 0\n",
    "for i in range(X_cat.shape[0]):\n",
    "    for j in range(len(X_cat_oh)):\n",
    "        if np.all(X_cat.values[i] == a[j][0]):\n",
    "            X_cat_n.insert(k, a[j][1])\n",
    "            k += 1\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разобьём на обучающую и тестовую выборку в соотношении 70/30\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train_real_zeros, X_test_real_zeros, y_train, y_test) = train_test_split(X_real_zeros, y, test_size = 0.3, random_state = 0)\n",
    "(X_train_cat_oh, X_test_cat_oh) = train_test_split(X_cat_n, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Соединим все признаки\n",
    "X_train_z = np.hstack([X_train_real_zeros, X_train_cat_oh])\n",
    "X_test_z = np.hstack([X_test_real_zeros, X_test_cat_oh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Воспользуемся логистической регрессией с L1-регуляризацией (задача бинарной классификации)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "optimizer_z = GridSearchCV(estimator = LogisticRegression(penalty='l1', solver='liblinear'), param_grid = param_grid)\n",
    "optimizer_z.fit(X_train_z, y_train)\n",
    "\n",
    "optimizer_z.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на веса при числовых признаках\n",
    "optimizer_z.best_estimator_.coef_.flatten()[0:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(lambda x : round(x, 2), optimizer_z.best_estimator_.coef_.flatten()[0:22])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посчитаем метрику ROC-AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_test = y_test.astype('int')\n",
    "y_z = optimizer_z.predict(X_test_z)\n",
    "auc_1 = roc_auc_score(y_test, y_z)\n",
    "auc_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы: признак hour меньше всего влияет на результат, его можно исключить из модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на данные, нужно масштабировать вещественные признаки\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "data_numeric = pd.DataFrame(X_train_real_zeros, columns=numeric_cols)\n",
    "list_cols = ['complex_value_size', 'tech_sms_cnt_3m', 'macro_state']\n",
    "scatter_matrix(data_numeric[list_cols], alpha=0.5, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Классы сбалансированны\n",
    "print(np.sum(y_train==0))\n",
    "print(np.sum(y_train==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Уберём признак hour из модели и разобьём на обучающую и тестовую выборку\n",
    "numeric_cols = list(set(data.columns.values.tolist()) - set(categorical_cols + ['target'] + ['tp_change_date'] + \n",
    "                                                            ['hour']))\n",
    "X_real_zeros = X[numeric_cols]\n",
    "X_real_zeros.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Масштабируем признаки и объединяем\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_real_scale = scale.fit_transform(X_real_zeros)\n",
    "\n",
    "X_real_scale = np.hstack([X_real_scale, X_cat_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучаем модель\n",
    "from sklearn import model_selection\n",
    "y = y.astype('int').values\n",
    "classifiers = []\n",
    "Y = []\n",
    "i = 0\n",
    "skf = model_selection.StratifiedKFold(n_splits = 7, shuffle = True, random_state = 0)\n",
    "for train_indices, test_indices in skf.split(X_real_scale, y):\n",
    "    param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "    x_tr = X_real_scale[train_indices]\n",
    "    y_tr = y[train_indices]\n",
    "    x_t = X_real_scale[test_indices]\n",
    "    y_t = y[test_indices]\n",
    "\n",
    "    optimizer_z = GridSearchCV(estimator = LogisticRegression(penalty='l2', solver='liblinear'), param_grid = param_grid)\n",
    "    optimizer_z.fit(x_tr, y_tr)\n",
    "    \n",
    "    y_z = optimizer_z.best_estimator_.predict_proba(x_t)[:,1]\n",
    "    Y.append([y_t, y_z])\n",
    "    classifiers.append(optimizer_z.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считаем метрику roc-auc\n",
    "auc = []\n",
    "for i in range(7):\n",
    "    auc.append(roc_auc_score(Y[i][0], Y[i][1]))\n",
    "np.array(auc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(c, k):\n",
    "    for i in range(len(c[1])):\n",
    "        if c[1][i] > k:\n",
    "            c[1][i] = 1\n",
    "        else:\n",
    "            c[1][i] = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    res(Y[i], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = []\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(Y)):\n",
    "    v.insert(i, confusion_matrix(Y[i][0], Y[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cnf_matrix):\n",
    "    return (cnf_matrix[0][0] + cnf_matrix[1][1])/ (cnf_matrix[0][1] + cnf_matrix[1][0] + cnf_matrix[0][0] + cnf_matrix[1][1])\n",
    "\n",
    "def recall(cnf_matrix):\n",
    "    return cnf_matrix[0][0] / (cnf_matrix[0][0] + cnf_matrix[1][0])\n",
    "\n",
    "def precision(cnf_matrix):\n",
    "    return cnf_matrix[0][0] / (cnf_matrix[0][0] + cnf_matrix[0][1])\n",
    "\n",
    "#and others :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(v)):\n",
    "    print('accuracy: {}, recall: {}, precision: {}'.format(accuracy(v[i]), recall(v[i]), precision(v[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сделаем предсказание - усреднение ответов классификаторов\n",
    "X = data2[numeric_cols + categorical_cols]\n",
    "\n",
    "X_real_zeros = X[numeric_cols]\n",
    "X_real_zeros.fillna(0, inplace = True)\n",
    "\n",
    "X_cat = X[categorical_cols]\n",
    "X_cat = pd.DataFrame(X_cat.fillna('NA'))\n",
    "\n",
    "a = []\n",
    "for i in range(235):\n",
    "    a.insert(i, [X_unic.values[i], X_cat_oh[i]])\n",
    "\n",
    "X_cat_n = []\n",
    "k = 0\n",
    "for i in range(X_cat.shape[0]):\n",
    "    for j in range(len(X_cat_oh)):\n",
    "        if np.all(X_cat.values[i] == a[j][0]):\n",
    "            X_cat_n.insert(k, a[j][1])\n",
    "            k += 1\n",
    "            break;         \n",
    "scale = StandardScaler()\n",
    "X_real_scale = scale.fit_transform(X_real_zeros)\n",
    "\n",
    "X_real_scale = np.hstack([X_real_scale, X_cat_n])\n",
    "YY = []\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    YY.append(classifiers[i].predict_proba(X_real_scale)[:,1])\n",
    "\n",
    "for i in range(len(YY)):\n",
    "    for j in range(len(YY[i])):\n",
    "        if YY[i][j] > 0.5:\n",
    "            YY[i][j] = 1\n",
    "        else:\n",
    "            YY[i][j] = 0\n",
    "\n",
    "res = sum(YY)\n",
    "\n",
    "for i in range(len(res)):\n",
    "    if res[i] >= 4:\n",
    "        res[i] = 1\n",
    "    else:\n",
    "        res[i] = 0\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как можно улучшить данную модель**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Проверка, что признаки не коррелируются между собой.**\n",
    "\n",
    "**2) Заполнить пропуски числовых признаков среднем арифметическим по столбу.**\n",
    "\n",
    "**3) Выбрать другой порог в логистической регрессии.**\n",
    "\n",
    "**4) Если есть возможность, то обучиться на большем количестве данных.**\n",
    "\n",
    "**5) Попробовать другие модели бинарной классификации (к примеру, метод опорных векторов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
